{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514a36b7",
   "metadata": {},
   "source": [
    "# *Web Scrapping Assignment - 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3756175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup               #we need these imports for all the questions\n",
    "import pandas as pd     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20eb419",
   "metadata": {},
   "source": [
    "## Question 1 - Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0c5bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Tag                         Content\n",
      "0  h1  WikipediaThe Free Encyclopedia\n",
      "1  h2              1 000 000+articles\n",
      "2  h2                100 000+articles\n",
      "3  h2                 10 000+articles\n",
      "4  h2                  1 000+articles\n",
      "5  h2                    100+articles\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.wikipedia.org/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "results = []\n",
    "for header in header_tags:\n",
    "    results.append({'Tag': header.name, 'Content': header.get_text()})\n",
    "    \n",
    "df = pd.DataFrame(results)\n",
    "df = df.replace('\\n', '', regex=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001881e",
   "metadata": {},
   "source": [
    "## Question 2 - Write a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5098f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Name  Rating  Year\n",
      "0                            The Shawshank Redemption     9.2  1994\n",
      "1                                       The Godfather     9.2  1972\n",
      "2                                     The Dark Knight     9.0  2008\n",
      "3                               The Godfather Part II     9.0  1974\n",
      "4                                        12 Angry Men     9.0  1957\n",
      "5                                    Schindler's List     8.9  1993\n",
      "6       The Lord of the Rings: The Return of the King     8.9  2003\n",
      "7                                        Pulp Fiction     8.8  1994\n",
      "8   The Lord of the Rings: The Fellowship of the Ring     8.8  2001\n",
      "9                     Il buono, il brutto, il cattivo     8.8  1966\n",
      "10                                       Forrest Gump     8.8  1994\n",
      "11                                         Fight Club     8.7  1999\n",
      "12              The Lord of the Rings: The Two Towers     8.7  2002\n",
      "13                                          Inception     8.7  2010\n",
      "14                            The Empire Strikes Back     8.7  1980\n",
      "15                                         The Matrix     8.7  1999\n",
      "16                                         GoodFellas     8.7  1990\n",
      "17                    One Flew Over the Cuckoo's Nest     8.6  1975\n",
      "18                                              Se7en     8.6  1995\n",
      "19                               Shichinin no samurai     8.6  1954\n",
      "20                              It's a Wonderful Life     8.6  1946\n",
      "21                           The Silence of the Lambs     8.6  1991\n",
      "22                                Saving Private Ryan     8.6  1998\n",
      "23                                     Cidade de Deus     8.6  2002\n",
      "24                                       Interstellar     8.6  2014\n",
      "25                                    La vita è bella     8.6  1997\n",
      "26                                     The Green Mile     8.6  1999\n",
      "27                                          Star Wars     8.5  1977\n",
      "28                         Terminator 2: Judgment Day     8.5  1991\n",
      "29                                 Back to the Future     8.5  1985\n",
      "30                      Sen to Chihiro no kamikakushi     8.5  2001\n",
      "31                                        The Pianist     8.5  2002\n",
      "32                                             Psycho     8.5  1960\n",
      "33                                       Gisaengchung     8.5  2019\n",
      "34                                               Léon     8.5  1994\n",
      "35                                      The Lion King     8.5  1994\n",
      "36                                          Gladiator     8.5  2000\n",
      "37                                 American History X     8.5  1998\n",
      "38                                       The Departed     8.5  2006\n",
      "39                                       The Prestige     8.5  2006\n",
      "40                                           Whiplash     8.5  2014\n",
      "41                                 The Usual Suspects     8.5  1995\n",
      "42                                         Casablanca     8.5  1942\n",
      "43                                     Hotaru no haka     8.5  1988\n",
      "44                                            Seppuku     8.5  1962\n",
      "45                                   The Intouchables     8.5  2011\n",
      "46                                       Modern Times     8.4  1936\n",
      "47                       Once Upon a Time in the West     8.4  1968\n",
      "48                              Nuovo Cinema Paradiso     8.4  1988\n",
      "49                                        Rear Window     8.4  1954\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.imdb.com/chart/top\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "movie_titles = [title.text for title in soup.select('td.titleColumn a')]\n",
    "movie_ratings = [float(rating.text.strip()) for rating in soup.select('td.ratingColumn strong')]\n",
    "movie_years = [int(year.text.strip('()')) for year in soup.select('td.titleColumn span.secondaryInfo')]\n",
    "\n",
    "movies_data = []\n",
    "\n",
    "for i in range(50):\n",
    "    movies_data.append({'Name': movie_titles[i], 'Rating': movie_ratings[i], 'Year': movie_years[i]})\n",
    "\n",
    "df = pd.DataFrame(movies_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb04cd8",
   "metadata": {},
   "source": [
    "## Question 3 - Write a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437cc9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Name  Rating  Year\n",
      "0   Ramayana: The Legend of Prince Rama     8.6  1993\n",
      "1            Rocketry: The Nambi Effect     8.4  2022\n",
      "2                               Nayakan     8.4  1987\n",
      "3                              Gol Maal     8.4  1979\n",
      "4                           777 Charlie     8.4  2022\n",
      "5                            Anbe Sivam     8.4  2003\n",
      "6                     Pariyerum Perumal     8.4  2018\n",
      "7                              Jai Bhim     8.4  2021\n",
      "8                              3 Idiots     8.4  2009\n",
      "9                           Apur Sansar     8.4  1959\n",
      "10                     Manichitrathazhu     8.3  1993\n",
      "11                                #Home     8.3  2021\n",
      "12                      Soorarai Pottru     8.3  2020\n",
      "13                         Black Friday     8.3  2004\n",
      "14                    Kumbalangi Nights     8.3  2019\n",
      "15                    C/o Kancharapalem     8.3  2018\n",
      "16                     Taare Zameen Par     8.3  2007\n",
      "17                             Kireedam     8.3  1989\n",
      "18                               Dangal     8.3  2016\n",
      "19                               Kaithi     8.3  2019\n",
      "20                               Jersey     8.3  2019\n",
      "21                                   96     8.3  2018\n",
      "22                          Maya Bazaar     8.2  1957\n",
      "23                            Natsamrat     8.2  2016\n",
      "24                           Drishyam 2     8.2  2021\n",
      "25                           Sita Ramam     8.2  2022\n",
      "26                               Asuran     8.2  2019\n",
      "27                         Thevar Magan     8.2  1992\n",
      "28                           Visaaranai     8.2  2015\n",
      "29                  Sarpatta Parambarai     8.2  2021\n",
      "30                           Thalapathi     8.2  1991\n",
      "31                         Nadodikkattu     8.2  1987\n",
      "32                      Pather Panchali     8.2  1955\n",
      "33                             Drishyam     8.2  2013\n",
      "34                         Thani Oruvan     8.2  2015\n",
      "35                   Jaane Bhi Do Yaaro     8.2  1983\n",
      "36                         Vada Chennai     8.2  2018\n",
      "37                            Aparajito     8.2  1956\n",
      "38                         Sardar Udham     8.2  2021\n",
      "39                    Khosla Ka Ghosla!     8.2  2006\n",
      "40                              Anniyan     8.2  2005\n",
      "41                             Ratsasan     8.1  2018\n",
      "42                        Chupke Chupke     8.1  1975\n",
      "43                   Gangs of Wasseypur     8.1  2012\n",
      "44                             Drishyam     8.1  2015\n",
      "45                              Peranbu     8.1  2018\n",
      "46                       Bangalore Days     8.1  2014\n",
      "47                             Mahanati     8.1  2018\n",
      "48                               Premam     8.1  2015\n",
      "49                                Satya     8.1  1998\n"
     ]
    }
   ],
   "source": [
    "#The code is same as above. We just need to change the url.\n",
    "\n",
    "url = \"https://www.imdb.com/india/top-rated-indian-movies/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "movie_titles = [title.text for title in soup.select('td.titleColumn a')]\n",
    "movie_ratings = [float(rating.text.strip()) for rating in soup.select('td.ratingColumn strong')]\n",
    "movie_years = [int(year.text.strip('()')) for year in soup.select('td.titleColumn span.secondaryInfo')]\n",
    "\n",
    "movies_data = []\n",
    "\n",
    "for i in range(50):\n",
    "    movies_data.append({'Name': movie_titles[i], 'Rating': movie_ratings[i], 'Year': movie_years[i]})\n",
    "\n",
    "df = pd.DataFrame(movies_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e584b6",
   "metadata": {},
   "source": [
    "## Question 4 - Write s python program to display list of respected former presidents of India (i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "626ac601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Name                                       Term of office\n",
      "        Shri Ram Nath Kovind (birth - 1945)       Term of Office: 25 July, 2017 to 25 July, 2022\n",
      "          Shri Pranab Mukherjee (1935-2020)                         https://ramnathkovind.nic.in\n",
      "Smt Pratibha Devisingh Patil (birth - 1934)       Term of Office: 25 July, 2012 to 25 July, 2017\n",
      "         DR. A.P.J. Abdul Kalam (1931-2015)                        http://pranabmukherjee.nic.in\n",
      "         Shri K. R. Narayanan (1920 - 2005)       Term of Office: 25 July, 2007 to 25 July, 2012\n",
      "        Dr Shankar Dayal Sharma (1918-1999)                          http://pratibhapatil.nic.in\n",
      "            Shri R Venkataraman (1910-2009)       Term of Office: 25 July, 2002 to 25 July, 2007\n",
      "               Giani Zail Singh (1916-1994)                             http://abdulkalam.nic.in\n",
      "      Shri Neelam Sanjiva Reddy (1913-1996)       Term of Office: 25 July, 1997 to 25 July, 2002\n",
      "       Dr. Fakhruddin Ali Ahmed (1905-1977)       Term of Office: 25 July, 1992 to 25 July, 1997\n",
      "   Shri Varahagiri Venkata Giri (1894-1980)       Term of Office: 25 July, 1987 to 25 July, 1992\n",
      "               Dr. Zakir Husain (1897-1969)       Term of Office: 25 July, 1982 to 25 July, 1987\n",
      "   Dr. Sarvepalli Radhakrishnan (1888-1975)       Term of Office: 25 July, 1977 to 25 July, 1982\n",
      "            Dr. Rajendra Prasad (1884-1963) Term of Office: 24 August, 1974 to 11 February, 1977\n"
     ]
    }
   ],
   "source": [
    "url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "president_names = [name.text.strip() for name in soup.select('h3')]\n",
    "president_terms = [term.text.strip() for term in soup.select('p')]\n",
    "\n",
    "presidents_data = []\n",
    "\n",
    "for i in range(len(president_names)):\n",
    "    presidents_data.append({'Name': president_names[i], 'Term of office': president_terms[i]})\n",
    "    \n",
    "df = pd.DataFrame(presidents_data)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff722e3b",
   "metadata": {},
   "source": [
    "## Question 5 - Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame \n",
    "#### a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "#### b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "#### c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c732b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams:\n",
      "       Team Name  Matches  Points  Ratings\n",
      "0     Australia       35    3965      113\n",
      "1         India       47    5294      113\n",
      "2   New Zealand       29    3229      111\n",
      "3       England       36    3988      111\n",
      "4      Pakistan       25    2649      106\n",
      "5  South Africa       29    2917      101\n",
      "6    Bangladesh       37    3520       95\n",
      "7     Sri Lanka       34    2976       88\n",
      "8   West Indies       43    3101       72\n",
      "9   Afghanistan       20    1419       71\n",
      "Top 10 ODI batsmen:\n",
      "              Player Name Team Name  Ratings\n",
      "0                   None      None      NaN\n",
      "1  Rassie van der Dussen        SA    777.0\n",
      "2            Imam-ul-Haq       PAK    740.0\n",
      "3        Quinton de Kock        SA    740.0\n",
      "4           Shubman Gill       IND    733.0\n",
      "5           David Warner       AUS    732.0\n",
      "6            Steve Smith       AUS    714.0\n",
      "7            Virat Kohli       IND    714.0\n",
      "8           Rohit Sharma       IND    704.0\n",
      "9        Kane Williamson        NZ    700.0\n",
      "Top 10 ODI bowlers:\n",
      "         Player Name Team Name  Ratings\n",
      "0              None      None      NaN\n",
      "1       Trent Boult        NZ    708.0\n",
      "2    Mohammed Siraj       IND    702.0\n",
      "3    Mitchell Starc       AUS    702.0\n",
      "4       Rashid Khan       AFG    659.0\n",
      "5   Shakib Al Hasan       BAN    648.0\n",
      "6    Shaheen Afridi       PAK    641.0\n",
      "7  Mujeeb Ur Rahman       AFG    637.0\n",
      "8        Adam Zampa       AUS    633.0\n",
      "9     Mohammad Nabi       AFG    631.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Scrape Top 10 ODI teams rankings\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "team_names = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find_all('table')[0]\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "for row in rows:\n",
    "    team_names.append(row.find('span', class_='u-hide-phablet').text.strip())\n",
    "    matches.append(int(row.find_all('td')[2].text))\n",
    "    points.append(int(row.find_all('td')[3].text.replace(',', '')))\n",
    "    ratings.append(int(row.find_all('td')[4].text))\n",
    "\n",
    "# Create Top 10 ODI teams data frame\n",
    "df_teams = pd.DataFrame({'Team Name': team_names,\n",
    "                         'Matches': matches,\n",
    "                         'Points': points,\n",
    "                         'Ratings': ratings})\n",
    "\n",
    "\n",
    "\n",
    "# Scrape Top 10 ODI batsmen rankings\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "player_names = []\n",
    "team_names = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find_all('table')[0]\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "for row in rows:\n",
    "    player_name_elem = row.find('td', class_='table-body__cell rankings-table__name name')\n",
    "    if player_name_elem is not None:\n",
    "        player_names.append(player_name_elem.text.strip())\n",
    "    else:\n",
    "        player_names.append(None)\n",
    "\n",
    "    team_name_elem = row.find('td', class_='table-body__cell nationality-logo rankings-table__team')\n",
    "    if team_name_elem is not None:\n",
    "        team_names.append(team_name_elem.text.strip())\n",
    "    else:\n",
    "        team_names.append(None)\n",
    "\n",
    "    rating_elem = row.find('td', class_='table-body__cell rating')\n",
    "    if rating_elem is not None:\n",
    "        ratings.append(int(rating_elem.text.strip()))\n",
    "    else:\n",
    "        ratings.append(None)\n",
    "\n",
    "\n",
    "# Create Top 10 ODI batsmen data frame\n",
    "df_batsmen = pd.DataFrame({'Player Name': player_names,\n",
    "                           'Team Name': team_names,\n",
    "                           'Ratings': ratings})\n",
    "\n",
    "\n",
    "\n",
    "# Scrape Top 10 ODI bowlers rankings\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "player_names = []\n",
    "team_names = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find_all('table')[0]\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "for row in rows:\n",
    "    player_name_elem = row.find('td', class_='table-body__cell rankings-table__name name')\n",
    "    if player_name_elem is not None:\n",
    "        player_names.append(player_name_elem.text.strip())\n",
    "    else:\n",
    "        player_names.append(None)\n",
    "\n",
    "    team_name_elem = row.find('span', class_='table-body__logo-text')\n",
    "    if team_name_elem is not None:\n",
    "        team_names.append(team_name_elem.text.strip())\n",
    "    else:\n",
    "        team_names.append(None)\n",
    "\n",
    "    rating_elem = row.find('td', class_='table-body__cell rating')\n",
    "    if rating_elem is not None:\n",
    "        ratings.append(int(rating_elem.text.strip()))\n",
    "    else:\n",
    "        ratings.append(None)\n",
    "\n",
    "\n",
    "# Create Top 10 ODI bowlers data frame\n",
    "df_bowlers = pd.DataFrame({'Player Name': player_names,\n",
    "                           'Team Name': team_names,\n",
    "                           'Ratings': ratings})\n",
    "\n",
    "# Print data frames\n",
    "print('Top 10 ODI teams:\\n', df_teams)\n",
    "print('Top 10 ODI batsmen:\\n', df_batsmen)\n",
    "print('Top 10 ODI bowlers:\\n', df_bowlers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f4fd7",
   "metadata": {},
   "source": [
    "## Question 6 - Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "#### a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#### b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "#### c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24103f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams:\n",
      "       Team Name  Matches  Points  Ratings\n",
      "0     Australia       21    3603      172\n",
      "1       England       28    3342      119\n",
      "2  South Africa       26    3098      119\n",
      "3         India       27    2820      104\n",
      "4   New Zealand       25    2553      102\n",
      "5   West Indies       27    2535       94\n",
      "6    Bangladesh       13     983       76\n",
      "7      Thailand        8     572       72\n",
      "8      Pakistan       27    1678       62\n",
      "9     Sri Lanka        8     353       44\n",
      "Top 10 ODI batsmen:\n",
      "            Player Name Team Name  Ratings\n",
      "0                 None      None      NaN\n",
      "1          Beth Mooney       AUS    754.0\n",
      "2      Laura Wolvaardt        SA    732.0\n",
      "3       Natalie Sciver       ENG    731.0\n",
      "4          Meg Lanning       AUS    717.0\n",
      "5     Harmanpreet Kaur       IND    716.0\n",
      "6      Smriti Mandhana       IND    714.0\n",
      "7       Rachael Haynes       AUS    680.0\n",
      "8  Chamari Athapaththu        SL    655.0\n",
      "9    Amy Satterthwaite        NZ    641.0\n",
      "Top 10 ODI bowlers:\n",
      "            Player Name Team Name  Ratings\n",
      "0                 None      None      NaN\n",
      "1        Jess Jonassen       AUS    723.0\n",
      "2       Shabnim Ismail        SA    722.0\n",
      "3         Megan Schutt       AUS    704.0\n",
      "4       Jhulan Goswami       IND    698.0\n",
      "5      Hayley Matthews        WI    660.0\n",
      "6           Kate Cross       ENG    655.0\n",
      "7       Ayabonga Khaka        SA    634.0\n",
      "8  Rajeshwari Gayakwad       IND    617.0\n",
      "9       Marizanne Kapp        SA    598.0\n"
     ]
    }
   ],
   "source": [
    "# The code is same as above. We just need to change the url.\n",
    "\n",
    "\n",
    "\n",
    "# Scrape Top 10 ODI teams rankings\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "team_names = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find_all('table')[0]\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "for row in rows:\n",
    "    team_names.append(row.find('span', class_='u-hide-phablet').text.strip())\n",
    "    matches.append(int(row.find_all('td')[2].text))\n",
    "    points.append(int(row.find_all('td')[3].text.replace(',', '')))\n",
    "    ratings.append(int(row.find_all('td')[4].text))\n",
    "\n",
    "# Create Top 10 ODI teams data frame\n",
    "df_teams = pd.DataFrame({'Team Name': team_names,\n",
    "                         'Matches': matches,\n",
    "                         'Points': points,\n",
    "                         'Ratings': ratings})\n",
    "\n",
    "\n",
    "\n",
    "# Scrape Top 10 ODI batsmen rankings\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "player_names = []\n",
    "team_names = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find_all('table')[0]\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "for row in rows:\n",
    "    player_name_elem = row.find('td', class_='table-body__cell rankings-table__name name')\n",
    "    if player_name_elem is not None:\n",
    "        player_names.append(player_name_elem.text.strip())\n",
    "    else:\n",
    "        player_names.append(None)\n",
    "\n",
    "    team_name_elem = row.find('td', class_='table-body__cell nationality-logo rankings-table__team')\n",
    "    if team_name_elem is not None:\n",
    "        team_names.append(team_name_elem.text.strip())\n",
    "    else:\n",
    "        team_names.append(None)\n",
    "\n",
    "    rating_elem = row.find('td', class_='table-body__cell rating')\n",
    "    if rating_elem is not None:\n",
    "        ratings.append(int(rating_elem.text.strip()))\n",
    "    else:\n",
    "        ratings.append(None)\n",
    "\n",
    "\n",
    "# Create Top 10 ODI batsmen data frame\n",
    "df_batsmen = pd.DataFrame({'Player Name': player_names,\n",
    "                           'Team Name': team_names,\n",
    "                           'Ratings': ratings})\n",
    "\n",
    "\n",
    "\n",
    "# Scrape Top 10 ODI bowlers rankings\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "player_names = []\n",
    "team_names = []\n",
    "ratings = []\n",
    "\n",
    "table = soup.find_all('table')[0]\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "for row in rows:\n",
    "    player_name_elem = row.find('td', class_='table-body__cell rankings-table__name name')\n",
    "    if player_name_elem is not None:\n",
    "        player_names.append(player_name_elem.text.strip())\n",
    "    else:\n",
    "        player_names.append(None)\n",
    "\n",
    "    team_name_elem = row.find('span', class_='table-body__logo-text')\n",
    "    if team_name_elem is not None:\n",
    "        team_names.append(team_name_elem.text.strip())\n",
    "    else:\n",
    "        team_names.append(None)\n",
    "\n",
    "    rating_elem = row.find('td', class_='table-body__cell rating')\n",
    "    if rating_elem is not None:\n",
    "        ratings.append(int(rating_elem.text.strip()))\n",
    "    else:\n",
    "        ratings.append(None)\n",
    "\n",
    "\n",
    "# Create Top 10 ODI bowlers data frame\n",
    "df_bowlers = pd.DataFrame({'Player Name': player_names,\n",
    "                           'Team Name': team_names,\n",
    "                           'Ratings': ratings})\n",
    "\n",
    "# Print data frames\n",
    "print('Top 10 ODI teams:\\n', df_teams)\n",
    "print('Top 10 ODI batsmen:\\n', df_batsmen)\n",
    "print('Top 10 ODI bowlers:\\n', df_bowlers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67d924",
   "metadata": {},
   "source": [
    "## Question 7 - Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n",
    "#### i)   Headline\n",
    "#### ii)  Time\n",
    "#### iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76a31536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                               Headline\n",
      "0                                   Treasury yields rise as investors weigh banking sector developments\n",
      "1                   Stock futures rise as First Citizens reaches Silicon Valley Bank deal: Live updates\n",
      "2   Explaining the relative calm of the stock market as the Fed hikes rates into a mini-financial panic\n",
      "3              Bitcoin’s March rally may be petering out. Here's where investors see it going from here\n",
      "4                 Rivian shares keep hitting all-time lows. Here's where Wall Street sees it going next\n",
      "5     'Sell into rallies': Morgan Stanley names the stocks to navigate current European banking jitters\n",
      "6                                 Here's how to spot a good growth stock, according to one fund manager\n",
      "7                                          Goldman's strategy to play the $3 trillion energy revolution\n",
      "8                       The A.I. boom could also give a boost to these investing trends. How to play it\n",
      "9   Russia stirs outrage with plan for tactical nukes in Belarus; Ukrainian town now 'post-apocalyptic'\n",
      "10                                                         The future of the U.S. military's tank force\n",
      "11          Russian strikes overnight kill civilians; Estonia calls China peace plan 'extremely unfair'\n",
      "12                           Estonia says China's peace plan to end Ukraine's war is 'extremely unfair'\n",
      "13                     China's liaisons with Russia are fueling an awkward split among European leaders\n",
      "14             A 'greenwashing' crackdown in Europe hasn't gone down well. Here's what you need to know\n",
      "15                                    Neste CEO: Sustainable aviation fuel aids supply chain efficiency\n",
      "16                          Europe's rush to LNG could turn into an ‘expensive and unnecessary’ mistake\n",
      "17                                 World’s top climate scientists issue a ‘survival guide for humanity’\n",
      "18                                  UK backs Rolls-Royce project to build a nuclear reactor on the moon\n",
      "19              Biden and Trudeau promote strength of democratic alliance on heels of Putin, Xi meeting\n",
      "20                           Pfizer's Covid drug Paxlovid may reduce the risk of long Covid, study says\n",
      "21                  Watch live: TikTok CEO testifies before House committee as potential U.S. ban looms\n",
      "22                              Watch live: Treasury Secretary Janet Yellen testifies at Senate hearing\n",
      "23                             Moderna CEO Stephane Bancel defends fivefold price hike of Covid vaccine\n",
      "24     Finland is the happiest country in the world. Now travelers can take a free trip to find out why\n",
      "25                     Traveling to Asia for work? This city is its most expensive business destination\n",
      "26                                   To escape the rat race, this pair cycled from Finland to Singapore\n",
      "27                                                          Here are the world's best airports for 2023\n",
      "28                                  Chinese tourists are traveling again — but not the way they used to\n",
      "29          3 red flags that prove it might be time to quit your job: 'Go out and make your own growth'\n",
      "30                         I went to my first Pilates class ever: 14 beginner moves you can try at home\n",
      "31                        Psychologist shares No. 1 exercise highly successful people use to be happier\n",
      "32                                                              Top 10 best U.S. cities to live in 2023\n",
      "33                               The 10 cheapest U.S. states to retire in—Florida barely makes the list\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "headlines = soup.find_all('a', class_='Card-title')\n",
    "\n",
    "news_data = []\n",
    "\n",
    "for i in range(len(headlines)):\n",
    "    headline = headlines[i].get_text().strip()\n",
    "    news_data.append([headline])\n",
    "\n",
    "df = pd.DataFrame(news_data, columns=['Headline'])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55da7df7",
   "metadata": {},
   "source": [
    "## Question 8 - Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "### Scrape below mentioned details and make data frame\n",
    "#### i) Paper Title\n",
    "#### ii) Authors\n",
    "#### iii) Published Date\n",
    "#### iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48fbd5a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       Name\n",
      "0                                                                                                                          Reward is enough\n",
      "1                                                                                                                 Making sense of raw input\n",
      "2                                                                                 Law and logic: A review from an argumentation perspective\n",
      "3                                                                                                    Creativity and artificial intelligence\n",
      "4                                                                Artificial cognition for social human–robot interaction: An implementation\n",
      "5                                                                 Explanation in artificial intelligence: Insights from the social sciences\n",
      "6                                                                                                             Making sense of sensory input\n",
      "7                                                                                 Conflict-based search for optimal multi-agent pathfinding\n",
      "8                                                Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning\n",
      "9                                                                                      The Hanabi challenge: A new frontier for AI research\n",
      "10                                                                Evaluating XAI: A comparison of rule-based and example-based explanations\n",
      "11                                                                                                 Argumentation in artificial intelligence\n",
      "12                                                                Algorithms for computing strategies in two-player simultaneous move games\n",
      "13                                                                                            Multiple object tracking: A literature review\n",
      "14                                                                          Selection of relevant features and examples in machine learning\n",
      "15                                                             A survey of inverse reinforcement learning: Challenges, methods and progress\n",
      "16                            Explaining individual predictions when features are dependent: More accurate approximations to Shapley values\n",
      "17                                 A review of possible effects of cognitive biases on interpretation of rule-based machine learning models\n",
      "18                                                                    Integrating social power into the decision-making of cognitive agents\n",
      "19                        “That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\n",
      "20  Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies\n",
      "21                                                                                       Algorithm runtime prediction: Methods & evaluation\n",
      "22                                                                                                    Wrappers for feature subset selection\n",
      "23   Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics\n",
      "24                                                                                               Quantum computation, quantum theory and AI\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "paper_title = [name.text.strip() for name in soup.select('h2', class_='sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg')]\n",
    "#president_terms = [term.text.strip() for term in soup.select('p')]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(len(paper_title)):\n",
    "    data.append({'Name': paper_title[i]})\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6108d",
   "metadata": {},
   "source": [
    "## Question 9 - Write a python program to scrape mentioned details from dineout.co.in and make data frame\n",
    "#### i) Restaurant name\n",
    "#### ii) Cuisine\n",
    "#### iii) Location\n",
    "#### iv) Ratings\n",
    "#### v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9a852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417f3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
